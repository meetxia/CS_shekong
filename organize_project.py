#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®æ–‡æ¡£æ•´ç†å’Œæµ‹è¯•æ–‡ä»¶æ¸…ç†è„šæœ¬
ç”¨é€”ï¼šæ•´ç† docs æ–‡ä»¶å¤¹ä¸­çš„æ–‡æ¡£ï¼Œæ¸…ç† test_ å¼€å¤´çš„æµ‹è¯•æ–‡ä»¶
"""

import os
import shutil
from pathlib import Path
from datetime import datetime
import json

class ProjectOrganizer:
    def __init__(self, workspace_path):
        self.workspace = Path(workspace_path)
        self.docs_path = self.workspace / 'docs'
        self.backup_path = self.workspace / 'backup'
        self.report = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'organized_files': [],
            'deleted_test_files': [],
            'moved_files': [],
            'errors': []
        }
    
    def create_backup(self):
        """åˆ›å»ºå¤‡ä»½æ–‡ä»¶å¤¹"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_dir = self.backup_path / f'backup_{timestamp}'
        backup_dir.mkdir(parents=True, exist_ok=True)
        return backup_dir
    
    def organize_docs(self, move_files=False):
        """æ•´ç† docs æ–‡ä»¶å¤¹ä¸­çš„æ–‡æ¡£"""
        print("ğŸ“ å¼€å§‹æ•´ç†æ–‡æ¡£...")
        
        if not self.docs_path.exists():
            print(f"âŒ æ–‡æ¡£æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {self.docs_path}")
            return
        
        # å®šä¹‰æ–‡æ¡£åˆ†ç±»è§„åˆ™ï¼ˆç›®å½•å -> å…³é”®è¯åˆ—è¡¨ï¼‰
        category_mapping = {
            '01-æ ¸å¿ƒæ–‡æ¡£': ['README', 'é¡¹ç›®äº¤ä»˜', 'åŠŸèƒ½æ¸…å•', 'éªŒæ”¶æ¸…å•', 'é¡¹ç›®å®Œæˆæ€»ç»“', 'é¡¹ç›®æ–‡ä»¶æ ‘'],
            '02-å¿«é€Ÿå¯åŠ¨æŒ‡å—': ['å¿«é€Ÿå¼€å§‹', 'å¿«é€Ÿæµ‹è¯•', 'å¼€å‘å¯åŠ¨', 'éƒ¨ç½²', 'å¿«é€Ÿ'],
            '03-ä¿®å¤æŠ¥å‘Š': ['ä¿®å¤', 'debug', 'fix', 'åŒæ­¥é—®é¢˜'],
            '04-åŠŸèƒ½å¼€å‘æŠ¥å‘Š': ['åŠŸèƒ½è¯´æ˜', 'åŠŸèƒ½å¼€å‘'],
            '05-ä¿®å¤æŠ¥å‘Š': ['ä¿®å¤æŠ¥å‘Š', 'ä¿®å¤æ­¥éª¤', 'ä¿®å¤æ€»ç»“'],
            '05-é¡¹ç›®ç®¡ç†æ–‡æ¡£': ['å°çº¢ä¹¦', 'MVP', 'ä¼˜åŒ–å»ºè®®'],
            '06-å¼€å‘è€…å·¥å…·': ['æµ‹è¯•', 'test'],
            '06-æ•°æ®åº“è„šæœ¬': ['æ•°æ®åº“', 'MySQL', 'SQL'],
            '07-èµ„æºæ–‡ä»¶': [],
            '08-å‘˜å·¥å·¥ä½œæ±‡æŠ¥': [],
            '09-é¡¹ç›®ç»ç†å·¥ä½œæ±‡æŠ¥': [],
        }
        
        # AIç›¸å…³æ–‡æ¡£ç‰¹æ®Šå¤„ç†ï¼ˆå¯ä»¥æ”¾åˆ°åŠŸèƒ½å¼€å‘æŠ¥å‘Šï¼‰
        ai_keywords = ['AI', 'Supabase', 'ä¾›åº”å•†é…ç½®', 'æç¤ºè¯', 'ç”Ÿæˆç¤ºä¾‹', 'å‘é€æ•°æ®']
        
        # æ¿€æ´»ç³»ç»Ÿç›¸å…³æ–‡æ¡£ï¼ˆå¯ä»¥æ”¾åˆ°ä¿®å¤æŠ¥å‘Šæˆ–åŠŸèƒ½å¼€å‘ï¼‰
        activation_keywords = ['æ¿€æ´»ç ', 'æ¿€æ´»çŠ¶æ€', 'æ¿€æ´»ç³»ç»Ÿ']
        
        # ä¼˜åŒ–æŠ¥å‘Šç›¸å…³
        optimization_keywords = ['ä¼˜åŒ–', 'æ”¹è¿›', 'æµ…è‰²æ¨¡å¼', 'é›·è¾¾å›¾', 'æµ‹è¯„é¡µé¢', 'é¢˜åº“', 'ç»“æœç®—æ³•', 'å¯¹æ¯”åº¦']
        
        # ä½¿ç”¨æŒ‡å—ç›¸å…³
        guide_keywords = ['ä½¿ç”¨æŒ‡å—', 'ä½¿ç”¨æ‰‹å†Œ', 'é›†æˆå®Œæˆ']
        
        # è·å–æ ¹ç›®å½•ä¸‹çš„æ‰€æœ‰ .md å’Œ .html æ–‡ä»¶ï¼ˆä¸åŒ…æ‹¬å­ç›®å½•ï¼‰
        root_files = [f for f in self.docs_path.glob('*') if f.is_file() and (f.suffix == '.md' or f.suffix == '.html' or f.suffix == '.txt')]
        
        print(f"\næ‰¾åˆ°æ ¹ç›®å½•ä¸‹ {len(root_files)} ä¸ªéœ€è¦æ•´ç†çš„æ–‡ä»¶")
        
        # ç»Ÿè®¡ç°æœ‰æ–‡ä»¶å¤¹
        existing_dirs = [d for d in self.docs_path.iterdir() if d.is_dir()]
        print(f"ç°æœ‰æ–‡ä»¶å¤¹: {len(existing_dirs)} ä¸ª\n")
        
        # åˆ†ç±»æ–‡ä»¶
        categorized = {}
        for file in root_files:
            category = self._categorize_file(file, category_mapping, ai_keywords, activation_keywords, optimization_keywords, guide_keywords)
            if category not in categorized:
                categorized[category] = []
            categorized[category].append(file)
        
        # æ˜¾ç¤ºåˆ†ç±»ç»“æœ
        print("ğŸ“‹ æ–‡æ¡£åˆ†ç±»ç»“æœï¼š\n")
        for category, files in sorted(categorized.items()):
            print(f"  ğŸ“‚ {category} ({len(files)} ä¸ªæ–‡ä»¶)")
            for f in files:
                print(f"     - {f.name}")
        
        # ç§»åŠ¨æ–‡ä»¶
        if move_files:
            print("\nğŸ“¦ å¼€å§‹ç§»åŠ¨æ–‡ä»¶...\n")
            for category, files in categorized.items():
                target_dir = self.docs_path / category
                target_dir.mkdir(exist_ok=True)
                
                for file in files:
                    try:
                        target_file = target_dir / file.name
                        if target_file.exists():
                            print(f"  âš ï¸  è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰: {file.name} -> {category}")
                            continue
                        
                        shutil.move(str(file), str(target_file))
                        self.report['moved_files'].append({
                            'file': file.name,
                            'from': 'docs/',
                            'to': f'docs/{category}/'
                        })
                        print(f"  âœ… å·²ç§»åŠ¨: {file.name} -> {category}")
                    except Exception as e:
                        error_msg = f"ç§»åŠ¨ {file.name} åˆ° {category} æ—¶å‡ºé”™: {str(e)}"
                        print(f"  âŒ {error_msg}")
                        self.report['errors'].append(error_msg)
            
            print(f"\nâœ… å·²ç§»åŠ¨ {sum(len(files) for files in categorized.values())} ä¸ªæ–‡ä»¶")
        else:
            print("\nâš ï¸  é¢„è§ˆæ¨¡å¼ - ä¸ä¼šç§»åŠ¨æ–‡ä»¶")
            print("ğŸ’¡ å¦‚éœ€ç§»åŠ¨æ–‡ä»¶ï¼Œè¯·è¿è¡Œ: python organize_project.py --organize")
        
        self.report['organized_files'].append({
            'total_root_files': len(root_files),
            'existing_directories': len(existing_dirs),
            'categorized': {cat: len(files) for cat, files in categorized.items()}
        })
    
    def _categorize_file(self, file, category_mapping, ai_keywords, activation_keywords, optimization_keywords, guide_keywords):
        """æ ¹æ®æ–‡ä»¶åæ™ºèƒ½åˆ†ç±»æ–‡æ¡£"""
        filename = file.name.lower()
        
        # AIç›¸å…³æ–‡æ¡£
        if any(keyword.lower() in filename for keyword in ai_keywords):
            if 'supabase' in filename and ('éƒ¨ç½²' in filename or 'å¿«é€Ÿ' in filename):
                return '02-å¿«é€Ÿå¯åŠ¨æŒ‡å—'
            return '04-åŠŸèƒ½å¼€å‘æŠ¥å‘Š'
        
        # æ¿€æ´»ç³»ç»Ÿç›¸å…³
        if any(keyword.lower() in filename for keyword in activation_keywords):
            if 'ä¿®å¤' in filename or 'debug' in filename or 'æ£€æŸ¥' in filename:
                return '03-ä¿®å¤æŠ¥å‘Š'
            elif 'æµ‹è¯•' in filename or 'test' in filename:
                return '06-å¼€å‘è€…å·¥å…·'
            elif 'ä½¿ç”¨æŒ‡å—' in filename:
                return '02-å¿«é€Ÿå¯åŠ¨æŒ‡å—'
            elif 'æµç¨‹å›¾' in filename or 'é€»è¾‘' in filename:
                return '04-åŠŸèƒ½å¼€å‘æŠ¥å‘Š'
            return '03-ä¿®å¤æŠ¥å‘Š'
        
        # ä¼˜åŒ–æŠ¥å‘Šç›¸å…³
        if any(keyword in filename for keyword in optimization_keywords):
            return '05-ä¿®å¤æŠ¥å‘Š'
        
        # ä½¿ç”¨æŒ‡å—ç›¸å…³
        if any(keyword in filename for keyword in guide_keywords):
            if 'ç®¡ç†å‘˜' in filename:
                return '02-å¿«é€Ÿå¯åŠ¨æŒ‡å—'
            return '04-åŠŸèƒ½å¼€å‘æŠ¥å‘Š'
        
        # æŒ‰ç…§é¢„å®šä¹‰çš„åˆ†ç±»è§„åˆ™
        for category, keywords in category_mapping.items():
            if any(keyword.lower() in filename for keyword in keywords):
                return category
        
        # ç‰¹æ®Šæ–‡ä»¶å¤„ç†
        if 'test-' in filename or 'test_' in filename:
            return '06-å¼€å‘è€…å·¥å…·'
        
        if 'å°çº¢ä¹¦' in filename or 'mvp' in filename:
            return '05-é¡¹ç›®ç®¡ç†æ–‡æ¡£'
        
        if 'æ‰£æ¬¡æ•°' in filename or 'æ¯æ—¥é™åˆ¶' in filename:
            return '03-ä¿®å¤æŠ¥å‘Š'
        
        if 'å¯¼èˆªæ ' in filename or 'é¦–é¡µ' in filename:
            return '04-åŠŸèƒ½å¼€å‘æŠ¥å‘Š'
        
        # é»˜è®¤æ”¾åˆ°æ ¸å¿ƒæ–‡æ¡£
        return '01-æ ¸å¿ƒæ–‡æ¡£'
    
    def find_test_files(self):
        """æŸ¥æ‰¾æ‰€æœ‰æµ‹è¯•æ–‡ä»¶"""
        print("\nğŸ” æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶...")
        
        test_patterns = ['test_*.js', 'test-*.js', 'test_*.ps1', 'test-*.html']
        test_files = []
        
        for pattern in test_patterns:
            files = list(self.workspace.glob(pattern))
            test_files.extend(files)
        
        # ä¹ŸæŸ¥æ‰¾ backend æ–‡ä»¶å¤¹ä¸­çš„æµ‹è¯•æ–‡ä»¶
        backend_path = self.workspace / 'backend'
        if backend_path.exists():
            for pattern in ['test_*.js', 'test-*.js']:
                files = list(backend_path.glob(pattern))
                test_files.extend(files)
        
        # å»é‡
        test_files = list(set(test_files))
        
        print(f"æ‰¾åˆ° {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶:")
        for f in test_files:
            size_kb = f.stat().st_size / 1024
            print(f"  ğŸ“„ {f.relative_to(self.workspace)} ({size_kb:.1f} KB)")
        
        return test_files
    
    def clean_test_files(self, delete=False):
        """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
        test_files = self.find_test_files()
        
        if not test_files:
            print("\nâœ… æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ¸…ç†çš„æµ‹è¯•æ–‡ä»¶")
            return
        
        if delete:
            print("\nğŸ—‘ï¸  å¼€å§‹æ¸…ç†æµ‹è¯•æ–‡ä»¶...")
            backup_dir = self.create_backup()
            backup_test_dir = backup_dir / 'test_files'
            backup_test_dir.mkdir(exist_ok=True)
            
            for test_file in test_files:
                try:
                    # å¤‡ä»½åˆ° backup æ–‡ä»¶å¤¹
                    relative_path = test_file.relative_to(self.workspace)
                    backup_file = backup_test_dir / relative_path.name
                    shutil.copy2(test_file, backup_file)
                    
                    # åˆ é™¤åŸæ–‡ä»¶
                    test_file.unlink()
                    
                    self.report['deleted_test_files'].append({
                        'file': str(relative_path),
                        'size_kb': test_file.stat().st_size / 1024 if test_file.exists() else 0,
                        'backup': str(backup_file.relative_to(self.workspace))
                    })
                    print(f"  âœ… å·²åˆ é™¤: {relative_path}")
                    
                except Exception as e:
                    error_msg = f"åˆ é™¤ {test_file} æ—¶å‡ºé”™: {str(e)}"
                    print(f"  âŒ {error_msg}")
                    self.report['errors'].append(error_msg)
            
            print(f"\nâœ… å·²åˆ é™¤ {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶")
            print(f"ğŸ“¦ å¤‡ä»½ä½ç½®: {backup_dir.relative_to(self.workspace)}")
        else:
            print("\nâš ï¸  é¢„è§ˆæ¨¡å¼ - ä¸ä¼šåˆ é™¤æ–‡ä»¶")
            print("ğŸ’¡ å¦‚éœ€åˆ é™¤ï¼Œè¯·è¿è¡Œ: python organize_project.py --delete")
    
    def generate_docs_index(self):
        """ç”Ÿæˆæ–‡æ¡£ç´¢å¼•"""
        print("\nğŸ“‹ ç”Ÿæˆæ–‡æ¡£ç´¢å¼•...")
        
        index_content = f"""# æ–‡æ¡£ç´¢å¼•

> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“ æ–‡æ¡£ç›®å½•ç»“æ„

"""
        
        total_files = 0
        
        # éå† docs æ–‡ä»¶å¤¹
        if self.docs_path.exists():
            # è·å–æ‰€æœ‰å­ç›®å½•å¹¶æ’åº
            subdirs = sorted([d for d in self.docs_path.iterdir() if d.is_dir()])
            
            for subdir in subdirs:
                # è·å–æ‰€æœ‰æ–‡ä»¶ï¼ˆä¸ä»…ä»…æ˜¯.mdï¼‰
                all_files = sorted([f for f in subdir.iterdir() if f.is_file()])
                file_count = len(all_files)
                total_files += file_count
                
                index_content += f"\n### ğŸ“‚ {subdir.name} ({file_count} ä¸ªæ–‡ä»¶)\n\n"
                
                if file_count > 0:
                    for file in all_files:
                        rel_path = file.relative_to(self.docs_path)
                        # æ ¹æ®æ–‡ä»¶ç±»å‹æ·»åŠ ä¸åŒçš„å›¾æ ‡
                        if file.suffix == '.md':
                            icon = 'ğŸ“'
                        elif file.suffix == '.html':
                            icon = 'ğŸŒ'
                        elif file.suffix == '.txt':
                            icon = 'ğŸ“„'
                        elif file.suffix == '.sql':
                            icon = 'ğŸ—„ï¸'
                        else:
                            icon = 'ğŸ“'
                        index_content += f"- {icon} [{file.name}](./{rel_path.as_posix()})\n"
                else:
                    index_content += "*ï¼ˆæš‚æ— æ–‡ä»¶ï¼‰*\n"
            
            # åˆ—å‡ºæ ¹ç›®å½•çš„æ–‡æ¡£
            root_files = sorted([f for f in self.docs_path.glob('*') if f.is_file() and f.name != 'INDEX.md'])
            if root_files:
                index_content += f"\n### ğŸ“„ æ ¹ç›®å½•æ–‡æ¡£ ({len(root_files)} ä¸ªæ–‡ä»¶)\n\n"
                for file in root_files:
                    if file.suffix == '.md':
                        icon = 'ğŸ“'
                    elif file.suffix == '.html':
                        icon = 'ğŸŒ'
                    else:
                        icon = 'ğŸ“'
                    index_content += f"- {icon} [{file.name}](./{file.name})\n"
                total_files += len(root_files)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        index_content += f"\n---\n\n**ğŸ“Š ç»Ÿè®¡**: å…± {len(subdirs)} ä¸ªç›®å½•ï¼Œ{total_files} ä¸ªæ–‡ä»¶\n"
        
        # ä¿å­˜ç´¢å¼•æ–‡ä»¶
        index_file = self.docs_path / 'INDEX.md'
        index_file.write_text(index_content, encoding='utf-8')
        print(f"âœ… æ–‡æ¡£ç´¢å¼•å·²ç”Ÿæˆ: {index_file.relative_to(self.workspace)}")
        print(f"   å…±ç´¢å¼• {len(subdirs)} ä¸ªç›®å½•ï¼Œ{total_files} ä¸ªæ–‡ä»¶")
    
    def save_report(self):
        """ä¿å­˜æ•´ç†æŠ¥å‘Š"""
        report_file = self.workspace / f'organize_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.report, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ“Š æ•´ç†æŠ¥å‘Šå·²ä¿å­˜: {report_file.name}")
    
    def run(self, delete_tests=False, organize_docs=False):
        """è¿è¡Œæ•´ç†æµç¨‹"""
        print("=" * 60)
        print("ğŸš€ é¡¹ç›®æ–‡æ¡£æ•´ç†å’Œæµ‹è¯•æ–‡ä»¶æ¸…ç†å·¥å…·")
        print("=" * 60)
        
        # æ•´ç†æ–‡æ¡£
        self.organize_docs(move_files=organize_docs)
        
        # ç”Ÿæˆæ–‡æ¡£ç´¢å¼•
        if organize_docs:
            self.generate_docs_index()
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if delete_tests or organize_docs:
            self.clean_test_files(delete=delete_tests)
        
        # ä¿å­˜æŠ¥å‘Š
        self.save_report()
        
        print("\n" + "=" * 60)
        print("âœ… æ•´ç†å®Œæˆ!")
        print("=" * 60)

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='é¡¹ç›®æ–‡æ¡£æ•´ç†å’Œæµ‹è¯•æ–‡ä»¶æ¸…ç†å·¥å…·')
    parser.add_argument('--delete', action='store_true', help='åˆ é™¤æµ‹è¯•æ–‡ä»¶ï¼ˆé»˜è®¤åªé¢„è§ˆï¼‰')
    parser.add_argument('--organize', action='store_true', help='æ•´ç†æ–‡æ¡£å¹¶ç§»åŠ¨åˆ°å¯¹åº”ç›®å½•ï¼ˆé»˜è®¤åªé¢„è§ˆï¼‰')
    parser.add_argument('--workspace', type=str, default='.', help='å·¥ä½œåŒºè·¯å¾„ï¼ˆé»˜è®¤ä¸ºå½“å‰ç›®å½•ï¼‰')
    
    args = parser.parse_args()
    
    workspace = Path(args.workspace).resolve()
    organizer = ProjectOrganizer(workspace)
    organizer.run(delete_tests=args.delete, organize_docs=args.organize)

if __name__ == '__main__':
    main()

